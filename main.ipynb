{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ffc827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_DIR = Path('./data')\n",
    "ADL_DIR = DATA_DIR / 'adl'\n",
    "FALL_DIR = DATA_DIR / 'fall'\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8\n",
    "NUM_FRAMES = 40\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fd2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_sequences(base_dir, label_name):\n",
    "    sequences = []\n",
    "    \n",
    "    for sequence_dir in sorted(base_dir.iterdir()):\n",
    "        if sequence_dir.is_dir():\n",
    "            frames = sorted(list(sequence_dir.glob('*.png')))\n",
    "            \n",
    "            if len(frames) > 0:\n",
    "                sequences.append({\n",
    "                    'sequence_name': sequence_dir.name,\n",
    "                    'path': sequence_dir,\n",
    "                    'num_frames': len(frames),\n",
    "                    'label': label_name\n",
    "                })\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "fall_sequences = explore_sequences(FALL_DIR, 'fall')\n",
    "adl_sequences = explore_sequences(ADL_DIR, 'adl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c626eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03f0e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FallDetectionDataset(Dataset):\n",
    "    def __init__(self, sequences, num_frames=40, transform=None):\n",
    "        self.sequences = sequences\n",
    "        self.num_frames = num_frames\n",
    "        self.transform = transform\n",
    "        self.label_map = {'fall': 1, 'adl': 0}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def _sample_frames(self, frame_paths):\n",
    "        total_frames = len(frame_paths)\n",
    "        \n",
    "        if total_frames <= self.num_frames:\n",
    "            indices = list(range(total_frames))\n",
    "            indices += [total_frames - 1] * (self.num_frames - total_frames)\n",
    "        else:\n",
    "            indices = np.linspace(0, total_frames - 1, self.num_frames, dtype=int)\n",
    "        \n",
    "        return [frame_paths[i] for i in indices]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_info = self.sequences[idx]\n",
    "        all_frames = sorted(list(seq_info['path'].glob('*.png')))\n",
    "        sampled_frames = self._sample_frames(all_frames)\n",
    "        \n",
    "        frames_tensors = []\n",
    "        for frame_path in sampled_frames:\n",
    "            img = Image.open(frame_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            frames_tensors.append(img)\n",
    "        \n",
    "        frames = torch.stack(frames_tensors)\n",
    "        label = self.label_map[seq_info['label']]\n",
    "        \n",
    "        return frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38dc9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_sequences = fall_sequences + adl_sequences\n",
    "\n",
    "train_val_sequences, test_sequences = train_test_split(\n",
    "    all_sequences,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=[seq['label'] for seq in all_sequences]\n",
    ")\n",
    "\n",
    "train_sequences, val_sequences = train_test_split(\n",
    "    train_val_sequences,\n",
    "    test_size=0.125,\n",
    "    random_state=SEED,\n",
    "    stratify=[seq['label'] for seq in train_val_sequences]\n",
    ")\n",
    "\n",
    "train_dataset = FallDetectionDataset(\n",
    "    train_sequences, \n",
    "    num_frames=NUM_FRAMES, \n",
    "    transform=train_transform  \n",
    ")\n",
    "\n",
    "val_dataset = FallDetectionDataset(\n",
    "    val_sequences, \n",
    "    num_frames=NUM_FRAMES, \n",
    "    transform=test_transform  \n",
    ")\n",
    "\n",
    "test_dataset = FallDetectionDataset(\n",
    "    test_sequences, \n",
    "    num_frames=NUM_FRAMES, \n",
    "    transform=test_transform \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e81daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class FallDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes=2, lstm_hidden=256, lstm_layers=2, dropout=0.5):\n",
    "        super(FallDetectionModel, self).__init__()\n",
    "        \n",
    "        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.feature_dim = 2048\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.feature_dim,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames, c, h, w = x.shape\n",
    "        \n",
    "        x = x.view(batch_size * num_frames, c, h, w)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.squeeze(-1).squeeze(-1)\n",
    "        x = x.view(batch_size, num_frames, self.feature_dim)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        x = lstm_out[:, -1, :]\n",
    "        \n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4322d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FallDetectionModel(\n",
    "    num_classes=2,\n",
    "    lstm_hidden=256,\n",
    "    lstm_layers=2,\n",
    "    dropout=0.5\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "total, trainable = count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43601163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 40, 3, 224, 224])\n",
      "Output shape: torch.Size([8, 2])\n",
      "Logits:\n",
      "tensor([[0.0664, 0.0741],\n",
      "        [0.0706, 0.0859],\n",
      "        [0.0401, 0.0927],\n",
      "        [0.0505, 0.0589],\n",
      "        [0.0498, 0.0757],\n",
      "        [0.0631, 0.0709],\n",
      "        [0.0654, 0.0626],\n",
      "        [0.0681, 0.0737]], device='cuda:0')\n",
      "\n",
      "Prawdopodobieństwa:\n",
      "tensor([[0.4981, 0.5019],\n",
      "        [0.4962, 0.5038],\n",
      "        [0.4869, 0.5131],\n",
      "        [0.4979, 0.5021],\n",
      "        [0.4935, 0.5065],\n",
      "        [0.4980, 0.5020],\n",
      "        [0.5007, 0.4993],\n",
      "        [0.4986, 0.5014]], device='cuda:0')\n",
      "\n",
      "Predykcje: tensor([1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "Prawdziwe: tensor([1, 1, 0, 0, 0, 1, 0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_batch_frames, test_batch_labels = next(iter(train_loader))\n",
    "\n",
    "print(f\"Input shape: {test_batch_frames.shape}\")\n",
    "\n",
    "test_batch_frames = test_batch_frames.to(device)\n",
    "test_batch_labels = test_batch_labels.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(test_batch_frames)\n",
    "\n",
    "print(f\"Output shape: {logits.shape}\")\n",
    "print(f\"Logits:\\n{logits}\")\n",
    "\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(f\"\\nPrawdopodobieństwa:\\n{probs}\")\n",
    "\n",
    "predictions = torch.argmax(logits, dim=1)\n",
    "print(f\"\\nPredykcje: {predictions}\")\n",
    "print(f\"Prawdziwe: {test_batch_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bba45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=True,    \n",
    "    min_lr=1e-7        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c574ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train() \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_frames, batch_labels in dataloader:\n",
    "        batch_frames = batch_frames.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_frames)\n",
    "        loss = criterion(logits, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_frames.size(0)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        correct += (predictions == batch_labels).sum().item()\n",
    "        total += batch_labels.size(0)\n",
    "    \n",
    "    avg_loss = running_loss / total\n",
    "    avg_acc = correct / total\n",
    "    \n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_frames, batch_labels in dataloader:\n",
    "            batch_frames = batch_frames.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            logits = model(batch_frames)\n",
    "            loss = criterion(logits, batch_labels)\n",
    "            \n",
    "            running_loss += loss.item() * batch_frames.size(0)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            correct += (predictions == batch_labels).sum().item()\n",
    "            total += batch_labels.size(0)\n",
    "            \n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / total\n",
    "    avg_acc = correct / total\n",
    "    \n",
    "    return avg_loss, avg_acc, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cfd9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                num_epochs, device, patience=5, save_model=True, model_path='best_model.pth'):\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoka {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc, _, _ = validate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "        print(f\"LR:         {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            if save_model:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_acc': val_acc,\n",
    "                }, model_path)\n",
    "            \n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            \n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"robimy early stopping po {epoch+1} epokach\")\n",
    "                break\n",
    "    \n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c66c7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(train_sequences, val_sequences, device, save_model=False):\n",
    "    train_dataset = FallDetectionDataset(\n",
    "        train_sequences,\n",
    "        num_frames=NUM_FRAMES,\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = FallDetectionDataset(\n",
    "        val_sequences,\n",
    "        num_frames=NUM_FRAMES,\n",
    "        transform=test_transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = FallDetectionModel().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=EPOCHS,\n",
    "        device=device,\n",
    "        patience=5,\n",
    "        save_model=save_model\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, preds, labels = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    return val_loss, val_acc, preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7b034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 1/10\n",
      "Train Loss: 0.6923 | Train Acc: 0.4493\n",
      "Val Loss:   0.7068 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6717 | Train Acc: 0.7101\n",
      "Val Loss:   0.6942 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6468 | Train Acc: 0.8261\n",
      "Val Loss:   0.6755 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6120 | Train Acc: 0.7826\n",
      "Val Loss:   0.6389 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5145 | Train Acc: 0.9565\n",
      "Val Loss:   0.5701 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3756 | Train Acc: 0.9565\n",
      "Val Loss:   0.4836 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2539 | Train Acc: 1.0000\n",
      "Val Loss:   0.3907 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.2239 | Train Acc: 0.9855\n",
      "Val Loss:   0.2838 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1386 | Train Acc: 0.9855\n",
      "Val Loss:   0.1816 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0874 | Train Acc: 1.0000\n",
      "Val Loss:   0.1112 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6904 | Train Acc: 0.5507\n",
      "Val Loss:   0.7132 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6782 | Train Acc: 0.7101\n",
      "Val Loss:   0.7019 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6501 | Train Acc: 0.8841\n",
      "Val Loss:   0.6672 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6072 | Train Acc: 0.9275\n",
      "Val Loss:   0.6113 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5142 | Train Acc: 1.0000\n",
      "Val Loss:   0.5348 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3665 | Train Acc: 1.0000\n",
      "Val Loss:   0.4255 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2193 | Train Acc: 1.0000\n",
      "Val Loss:   0.2904 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1207 | Train Acc: 1.0000\n",
      "Val Loss:   0.1628 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0618 | Train Acc: 1.0000\n",
      "Val Loss:   0.0795 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1371 | Train Acc: 0.9565\n",
      "Val Loss:   0.0447 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6825 | Train Acc: 0.5797\n",
      "Val Loss:   0.7735 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6746 | Train Acc: 0.5797\n",
      "Val Loss:   0.7586 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6623 | Train Acc: 0.5797\n",
      "Val Loss:   0.7361 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6357 | Train Acc: 0.6087\n",
      "Val Loss:   0.6889 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5827 | Train Acc: 0.7536\n",
      "Val Loss:   0.6303 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4722 | Train Acc: 0.9855\n",
      "Val Loss:   0.5171 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2992 | Train Acc: 1.0000\n",
      "Val Loss:   0.3241 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1418 | Train Acc: 1.0000\n",
      "Val Loss:   0.1707 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0941 | Train Acc: 0.9855\n",
      "Val Loss:   0.0821 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0404 | Train Acc: 1.0000\n",
      "Val Loss:   0.0415 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6928 | Train Acc: 0.5217\n",
      "Val Loss:   0.6876 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6847 | Train Acc: 0.6377\n",
      "Val Loss:   0.6825 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6602 | Train Acc: 0.9275\n",
      "Val Loss:   0.6496 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6299 | Train Acc: 0.9565\n",
      "Val Loss:   0.5909 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5680 | Train Acc: 1.0000\n",
      "Val Loss:   0.5047 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4341 | Train Acc: 1.0000\n",
      "Val Loss:   0.3159 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2323 | Train Acc: 1.0000\n",
      "Val Loss:   0.1554 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1079 | Train Acc: 1.0000\n",
      "Val Loss:   0.0653 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0542 | Train Acc: 1.0000\n",
      "Val Loss:   0.0308 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0296 | Train Acc: 1.0000\n",
      "Val Loss:   0.0166 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6918 | Train Acc: 0.5507\n",
      "Val Loss:   0.6848 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6795 | Train Acc: 0.7246\n",
      "Val Loss:   0.6659 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6619 | Train Acc: 0.8696\n",
      "Val Loss:   0.6526 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6352 | Train Acc: 0.9710\n",
      "Val Loss:   0.6145 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5740 | Train Acc: 1.0000\n",
      "Val Loss:   0.5431 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4597 | Train Acc: 1.0000\n",
      "Val Loss:   0.4073 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2772 | Train Acc: 1.0000\n",
      "Val Loss:   0.2437 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1268 | Train Acc: 1.0000\n",
      "Val Loss:   0.1223 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0580 | Train Acc: 1.0000\n",
      "Val Loss:   0.0581 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0361 | Train Acc: 1.0000\n",
      "Val Loss:   0.0283 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6834 | Train Acc: 0.6957\n",
      "Val Loss:   0.7145 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6661 | Train Acc: 0.7101\n",
      "Val Loss:   0.6969 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6421 | Train Acc: 0.8406\n",
      "Val Loss:   0.6535 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5803 | Train Acc: 0.9855\n",
      "Val Loss:   0.5918 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4754 | Train Acc: 0.9855\n",
      "Val Loss:   0.5029 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3147 | Train Acc: 1.0000\n",
      "Val Loss:   0.3648 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1928 | Train Acc: 1.0000\n",
      "Val Loss:   0.2258 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1063 | Train Acc: 1.0000\n",
      "Val Loss:   0.1242 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0607 | Train Acc: 1.0000\n",
      "Val Loss:   0.0633 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0355 | Train Acc: 1.0000\n",
      "Val Loss:   0.0313 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.7024 | Train Acc: 0.4203\n",
      "Val Loss:   0.6442 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6878 | Train Acc: 0.4638\n",
      "Val Loss:   0.6374 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6698 | Train Acc: 0.5942\n",
      "Val Loss:   0.6239 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6288 | Train Acc: 0.8986\n",
      "Val Loss:   0.5843 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5657 | Train Acc: 1.0000\n",
      "Val Loss:   0.5096 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4189 | Train Acc: 1.0000\n",
      "Val Loss:   0.4070 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2259 | Train Acc: 1.0000\n",
      "Val Loss:   0.2421 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1215 | Train Acc: 1.0000\n",
      "Val Loss:   0.1389 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1192 | Train Acc: 0.9855\n",
      "Val Loss:   0.0691 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0326 | Train Acc: 1.0000\n",
      "Val Loss:   0.0367 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6806 | Train Acc: 0.6667\n",
      "Val Loss:   0.7203 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6675 | Train Acc: 0.6667\n",
      "Val Loss:   0.7099 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6488 | Train Acc: 0.6957\n",
      "Val Loss:   0.6949 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5880 | Train Acc: 0.9710\n",
      "Val Loss:   0.6419 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4964 | Train Acc: 0.9565\n",
      "Val Loss:   0.5490 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3333 | Train Acc: 1.0000\n",
      "Val Loss:   0.3951 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1912 | Train Acc: 1.0000\n",
      "Val Loss:   0.2317 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1111 | Train Acc: 1.0000\n",
      "Val Loss:   0.1163 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0549 | Train Acc: 1.0000\n",
      "Val Loss:   0.0547 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0293 | Train Acc: 1.0000\n",
      "Val Loss:   0.0270 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6832 | Train Acc: 0.5797\n",
      "Val Loss:   0.7845 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6641 | Train Acc: 0.5797\n",
      "Val Loss:   0.7751 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6464 | Train Acc: 0.5797\n",
      "Val Loss:   0.7373 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5912 | Train Acc: 0.7391\n",
      "Val Loss:   0.6534 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5037 | Train Acc: 0.9420\n",
      "Val Loss:   0.5222 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3584 | Train Acc: 1.0000\n",
      "Val Loss:   0.3269 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1869 | Train Acc: 1.0000\n",
      "Val Loss:   0.1508 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0754 | Train Acc: 1.0000\n",
      "Val Loss:   0.0691 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0382 | Train Acc: 1.0000\n",
      "Val Loss:   0.0340 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0201 | Train Acc: 1.0000\n",
      "Val Loss:   0.0185 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6808 | Train Acc: 0.5797\n",
      "Val Loss:   0.7219 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6629 | Train Acc: 0.5942\n",
      "Val Loss:   0.7126 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6452 | Train Acc: 0.6522\n",
      "Val Loss:   0.6839 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6023 | Train Acc: 0.8841\n",
      "Val Loss:   0.6026 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5206 | Train Acc: 1.0000\n",
      "Val Loss:   0.4850 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3571 | Train Acc: 1.0000\n",
      "Val Loss:   0.3292 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1970 | Train Acc: 1.0000\n",
      "Val Loss:   0.1798 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0973 | Train Acc: 1.0000\n",
      "Val Loss:   0.0920 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0517 | Train Acc: 1.0000\n",
      "Val Loss:   0.0461 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0338 | Train Acc: 1.0000\n",
      "Val Loss:   0.0249 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6959 | Train Acc: 0.4203\n",
      "Val Loss:   0.6417 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6809 | Train Acc: 0.5072\n",
      "Val Loss:   0.6554 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6585 | Train Acc: 0.7971\n",
      "Val Loss:   0.6285 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6106 | Train Acc: 0.9275\n",
      "Val Loss:   0.5586 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5341 | Train Acc: 1.0000\n",
      "Val Loss:   0.4519 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3889 | Train Acc: 1.0000\n",
      "Val Loss:   0.2603 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2276 | Train Acc: 1.0000\n",
      "Val Loss:   0.1245 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1037 | Train Acc: 1.0000\n",
      "Val Loss:   0.0596 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0559 | Train Acc: 1.0000\n",
      "Val Loss:   0.0280 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0320 | Train Acc: 1.0000\n",
      "Val Loss:   0.0157 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6864 | Train Acc: 0.5942\n",
      "Val Loss:   0.6890 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6712 | Train Acc: 0.7971\n",
      "Val Loss:   0.6817 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6605 | Train Acc: 0.7971\n",
      "Val Loss:   0.6709 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6254 | Train Acc: 0.9130\n",
      "Val Loss:   0.6234 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5472 | Train Acc: 1.0000\n",
      "Val Loss:   0.5391 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3880 | Train Acc: 1.0000\n",
      "Val Loss:   0.3519 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2306 | Train Acc: 1.0000\n",
      "Val Loss:   0.1826 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1150 | Train Acc: 1.0000\n",
      "Val Loss:   0.0855 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0586 | Train Acc: 1.0000\n",
      "Val Loss:   0.0410 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0467 | Train Acc: 0.9855\n",
      "Val Loss:   0.0207 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6942 | Train Acc: 0.4928\n",
      "Val Loss:   0.6652 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6814 | Train Acc: 0.5942\n",
      "Val Loss:   0.6467 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6600 | Train Acc: 0.8261\n",
      "Val Loss:   0.6114 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6264 | Train Acc: 0.9275\n",
      "Val Loss:   0.5733 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5398 | Train Acc: 1.0000\n",
      "Val Loss:   0.4913 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3899 | Train Acc: 1.0000\n",
      "Val Loss:   0.3468 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2108 | Train Acc: 1.0000\n",
      "Val Loss:   0.2104 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1083 | Train Acc: 1.0000\n",
      "Val Loss:   0.1126 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0574 | Train Acc: 1.0000\n",
      "Val Loss:   0.0577 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0743 | Train Acc: 0.9855\n",
      "Val Loss:   0.0342 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6940 | Train Acc: 0.4928\n",
      "Val Loss:   0.6551 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6773 | Train Acc: 0.7101\n",
      "Val Loss:   0.6438 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6510 | Train Acc: 0.9130\n",
      "Val Loss:   0.6210 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5958 | Train Acc: 0.9565\n",
      "Val Loss:   0.5879 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4821 | Train Acc: 1.0000\n",
      "Val Loss:   0.5114 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3241 | Train Acc: 1.0000\n",
      "Val Loss:   0.4188 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1978 | Train Acc: 1.0000\n",
      "Val Loss:   0.3127 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1227 | Train Acc: 1.0000\n",
      "Val Loss:   0.1967 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0701 | Train Acc: 1.0000\n",
      "Val Loss:   0.0971 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0346 | Train Acc: 1.0000\n",
      "Val Loss:   0.0442 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6916 | Train Acc: 0.5072\n",
      "Val Loss:   0.7219 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6723 | Train Acc: 0.6667\n",
      "Val Loss:   0.7192 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6421 | Train Acc: 0.7681\n",
      "Val Loss:   0.6914 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5985 | Train Acc: 0.8696\n",
      "Val Loss:   0.6329 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5082 | Train Acc: 0.9420\n",
      "Val Loss:   0.5720 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3779 | Train Acc: 0.9855\n",
      "Val Loss:   0.4926 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2278 | Train Acc: 1.0000\n",
      "Val Loss:   0.3884 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1600 | Train Acc: 1.0000\n",
      "Val Loss:   0.2664 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1030 | Train Acc: 1.0000\n",
      "Val Loss:   0.1474 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0581 | Train Acc: 1.0000\n",
      "Val Loss:   0.0734 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.7020 | Train Acc: 0.4203\n",
      "Val Loss:   0.6619 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6867 | Train Acc: 0.4928\n",
      "Val Loss:   0.6420 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6654 | Train Acc: 0.7391\n",
      "Val Loss:   0.6183 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6413 | Train Acc: 0.8986\n",
      "Val Loss:   0.5766 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5842 | Train Acc: 0.9855\n",
      "Val Loss:   0.4948 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4641 | Train Acc: 1.0000\n",
      "Val Loss:   0.3518 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2931 | Train Acc: 1.0000\n",
      "Val Loss:   0.1865 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1345 | Train Acc: 1.0000\n",
      "Val Loss:   0.0932 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0667 | Train Acc: 1.0000\n",
      "Val Loss:   0.0426 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1192 | Train Acc: 0.9710\n",
      "Val Loss:   0.0224 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6796 | Train Acc: 0.5797\n",
      "Val Loss:   0.7650 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6653 | Train Acc: 0.5942\n",
      "Val Loss:   0.7532 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6403 | Train Acc: 0.5797\n",
      "Val Loss:   0.7262 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5898 | Train Acc: 0.6522\n",
      "Val Loss:   0.6753 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4748 | Train Acc: 0.8696\n",
      "Val Loss:   0.6029 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3481 | Train Acc: 1.0000\n",
      "Val Loss:   0.4610 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2918 | Train Acc: 0.9710\n",
      "Val Loss:   0.3105 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1915 | Train Acc: 0.9565\n",
      "Val Loss:   0.2029 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0988 | Train Acc: 1.0000\n",
      "Val Loss:   0.1115 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1278 | Train Acc: 0.9565\n",
      "Val Loss:   0.0748 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.7033 | Train Acc: 0.4203\n",
      "Val Loss:   0.6246 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6831 | Train Acc: 0.5797\n",
      "Val Loss:   0.6295 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6637 | Train Acc: 0.7536\n",
      "Val Loss:   0.6142 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6257 | Train Acc: 0.9130\n",
      "Val Loss:   0.5821 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5496 | Train Acc: 1.0000\n",
      "Val Loss:   0.5142 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3833 | Train Acc: 1.0000\n",
      "Val Loss:   0.4101 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2300 | Train Acc: 0.9855\n",
      "Val Loss:   0.2815 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1734 | Train Acc: 0.9855\n",
      "Val Loss:   0.1719 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0841 | Train Acc: 1.0000\n",
      "Val Loss:   0.0951 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0515 | Train Acc: 1.0000\n",
      "Val Loss:   0.0518 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6853 | Train Acc: 0.6087\n",
      "Val Loss:   0.7210 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6703 | Train Acc: 0.6087\n",
      "Val Loss:   0.7048 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6483 | Train Acc: 0.6232\n",
      "Val Loss:   0.6872 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6046 | Train Acc: 0.7101\n",
      "Val Loss:   0.6501 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5190 | Train Acc: 0.9275\n",
      "Val Loss:   0.5818 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3730 | Train Acc: 1.0000\n",
      "Val Loss:   0.4593 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2906 | Train Acc: 0.9710\n",
      "Val Loss:   0.3464 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1614 | Train Acc: 1.0000\n",
      "Val Loss:   0.2280 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1412 | Train Acc: 0.9710\n",
      "Val Loss:   0.1380 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0628 | Train Acc: 1.0000\n",
      "Val Loss:   0.0823 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6849 | Train Acc: 0.5942\n",
      "Val Loss:   0.7403 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6760 | Train Acc: 0.5797\n",
      "Val Loss:   0.7290 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6573 | Train Acc: 0.6522\n",
      "Val Loss:   0.7096 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6333 | Train Acc: 0.6957\n",
      "Val Loss:   0.6798 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5788 | Train Acc: 0.8696\n",
      "Val Loss:   0.6040 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4578 | Train Acc: 1.0000\n",
      "Val Loss:   0.4634 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2891 | Train Acc: 1.0000\n",
      "Val Loss:   0.2703 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1895 | Train Acc: 0.9565\n",
      "Val Loss:   0.1525 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1943 | Train Acc: 0.9420\n",
      "Val Loss:   0.0907 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0527 | Train Acc: 1.0000\n",
      "Val Loss:   0.0653 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6803 | Train Acc: 0.6522\n",
      "Val Loss:   0.7124 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6648 | Train Acc: 0.7101\n",
      "Val Loss:   0.6909 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6434 | Train Acc: 0.8551\n",
      "Val Loss:   0.6438 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5953 | Train Acc: 0.9275\n",
      "Val Loss:   0.5561 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5252 | Train Acc: 0.9710\n",
      "Val Loss:   0.4233 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3700 | Train Acc: 1.0000\n",
      "Val Loss:   0.2737 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1932 | Train Acc: 1.0000\n",
      "Val Loss:   0.1387 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1205 | Train Acc: 0.9855\n",
      "Val Loss:   0.0688 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0520 | Train Acc: 1.0000\n",
      "Val Loss:   0.0412 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0326 | Train Acc: 1.0000\n",
      "Val Loss:   0.0255 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6859 | Train Acc: 0.5942\n",
      "Val Loss:   0.6994 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6752 | Train Acc: 0.7101\n",
      "Val Loss:   0.6902 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6419 | Train Acc: 0.8406\n",
      "Val Loss:   0.6652 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6066 | Train Acc: 0.8841\n",
      "Val Loss:   0.6178 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5251 | Train Acc: 0.9855\n",
      "Val Loss:   0.5424 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3566 | Train Acc: 1.0000\n",
      "Val Loss:   0.4050 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2020 | Train Acc: 1.0000\n",
      "Val Loss:   0.2565 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.2099 | Train Acc: 0.9710\n",
      "Val Loss:   0.1404 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0663 | Train Acc: 1.0000\n",
      "Val Loss:   0.0681 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0997 | Train Acc: 0.9855\n",
      "Val Loss:   0.0356 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6858 | Train Acc: 0.5652\n",
      "Val Loss:   0.7693 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6745 | Train Acc: 0.5797\n",
      "Val Loss:   0.7378 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6496 | Train Acc: 0.5942\n",
      "Val Loss:   0.6987 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6120 | Train Acc: 0.8406\n",
      "Val Loss:   0.6368 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5431 | Train Acc: 0.9420\n",
      "Val Loss:   0.5262 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3807 | Train Acc: 1.0000\n",
      "Val Loss:   0.3409 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2410 | Train Acc: 0.9710\n",
      "Val Loss:   0.1815 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1516 | Train Acc: 0.9855\n",
      "Val Loss:   0.0967 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1856 | Train Acc: 0.9420\n",
      "Val Loss:   0.0714 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0441 | Train Acc: 1.0000\n",
      "Val Loss:   0.0570 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6962 | Train Acc: 0.4203\n",
      "Val Loss:   0.6691 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6814 | Train Acc: 0.6232\n",
      "Val Loss:   0.6559 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6667 | Train Acc: 0.7971\n",
      "Val Loss:   0.6379 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6428 | Train Acc: 0.9565\n",
      "Val Loss:   0.6164 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5757 | Train Acc: 0.9710\n",
      "Val Loss:   0.5611 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4468 | Train Acc: 1.0000\n",
      "Val Loss:   0.4735 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2803 | Train Acc: 1.0000\n",
      "Val Loss:   0.3418 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1576 | Train Acc: 1.0000\n",
      "Val Loss:   0.2072 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.2033 | Train Acc: 0.9710\n",
      "Val Loss:   0.1047 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1811 | Train Acc: 0.9565\n",
      "Val Loss:   0.0584 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6823 | Train Acc: 0.5797\n",
      "Val Loss:   0.7521 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6671 | Train Acc: 0.5797\n",
      "Val Loss:   0.7293 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6478 | Train Acc: 0.6087\n",
      "Val Loss:   0.7003 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5873 | Train Acc: 0.7971\n",
      "Val Loss:   0.6227 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4947 | Train Acc: 1.0000\n",
      "Val Loss:   0.4723 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3447 | Train Acc: 1.0000\n",
      "Val Loss:   0.2722 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1768 | Train Acc: 1.0000\n",
      "Val Loss:   0.1249 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0859 | Train Acc: 1.0000\n",
      "Val Loss:   0.0551 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0359 | Train Acc: 1.0000\n",
      "Val Loss:   0.0278 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0200 | Train Acc: 1.0000\n",
      "Val Loss:   0.0153 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6905 | Train Acc: 0.5942\n",
      "Val Loss:   0.6996 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6743 | Train Acc: 0.7826\n",
      "Val Loss:   0.6824 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6625 | Train Acc: 0.8261\n",
      "Val Loss:   0.6580 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6317 | Train Acc: 0.9710\n",
      "Val Loss:   0.5938 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5563 | Train Acc: 1.0000\n",
      "Val Loss:   0.4894 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4409 | Train Acc: 1.0000\n",
      "Val Loss:   0.3128 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2669 | Train Acc: 0.9855\n",
      "Val Loss:   0.1627 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1216 | Train Acc: 1.0000\n",
      "Val Loss:   0.0749 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0617 | Train Acc: 1.0000\n",
      "Val Loss:   0.0349 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0308 | Train Acc: 1.0000\n",
      "Val Loss:   0.0178 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6784 | Train Acc: 0.5797\n",
      "Val Loss:   0.7528 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6675 | Train Acc: 0.5797\n",
      "Val Loss:   0.7429 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6455 | Train Acc: 0.5942\n",
      "Val Loss:   0.7121 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6025 | Train Acc: 0.7681\n",
      "Val Loss:   0.6612 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5081 | Train Acc: 0.8551\n",
      "Val Loss:   0.5632 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3525 | Train Acc: 1.0000\n",
      "Val Loss:   0.4282 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2030 | Train Acc: 1.0000\n",
      "Val Loss:   0.2776 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1250 | Train Acc: 1.0000\n",
      "Val Loss:   0.1346 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.2189 | Train Acc: 0.9565\n",
      "Val Loss:   0.0707 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.3025 | Train Acc: 0.9130\n",
      "Val Loss:   0.0721 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6938 | Train Acc: 0.4928\n",
      "Val Loss:   0.6869 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6815 | Train Acc: 0.7246\n",
      "Val Loss:   0.6793 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6655 | Train Acc: 0.8841\n",
      "Val Loss:   0.6626 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6344 | Train Acc: 0.8841\n",
      "Val Loss:   0.6388 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5909 | Train Acc: 0.8551\n",
      "Val Loss:   0.5831 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4512 | Train Acc: 0.9855\n",
      "Val Loss:   0.4986 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.3333 | Train Acc: 0.9710\n",
      "Val Loss:   0.4043 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1967 | Train Acc: 1.0000\n",
      "Val Loss:   0.2924 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1235 | Train Acc: 1.0000\n",
      "Val Loss:   0.1726 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1103 | Train Acc: 0.9855\n",
      "Val Loss:   0.0954 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6915 | Train Acc: 0.5072\n",
      "Val Loss:   0.7064 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6793 | Train Acc: 0.6957\n",
      "Val Loss:   0.6869 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6638 | Train Acc: 0.7826\n",
      "Val Loss:   0.6570 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6446 | Train Acc: 0.9420\n",
      "Val Loss:   0.5962 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5873 | Train Acc: 1.0000\n",
      "Val Loss:   0.5102 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4848 | Train Acc: 1.0000\n",
      "Val Loss:   0.3535 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2994 | Train Acc: 1.0000\n",
      "Val Loss:   0.1951 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.2200 | Train Acc: 0.9710\n",
      "Val Loss:   0.0961 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1427 | Train Acc: 0.9855\n",
      "Val Loss:   0.0545 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0929 | Train Acc: 0.9855\n",
      "Val Loss:   0.0332 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6937 | Train Acc: 0.4638\n",
      "Val Loss:   0.6779 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6837 | Train Acc: 0.6522\n",
      "Val Loss:   0.6672 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6632 | Train Acc: 0.9275\n",
      "Val Loss:   0.6459 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6306 | Train Acc: 0.9855\n",
      "Val Loss:   0.6031 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5518 | Train Acc: 0.9855\n",
      "Val Loss:   0.5315 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4005 | Train Acc: 1.0000\n",
      "Val Loss:   0.4165 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2293 | Train Acc: 1.0000\n",
      "Val Loss:   0.2715 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1394 | Train Acc: 1.0000\n",
      "Val Loss:   0.1554 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0787 | Train Acc: 1.0000\n",
      "Val Loss:   0.0774 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0454 | Train Acc: 1.0000\n",
      "Val Loss:   0.0381 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6858 | Train Acc: 0.6522\n",
      "Val Loss:   0.6567 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6702 | Train Acc: 0.8696\n",
      "Val Loss:   0.6312 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6526 | Train Acc: 0.9130\n",
      "Val Loss:   0.6001 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6048 | Train Acc: 0.9855\n",
      "Val Loss:   0.5234 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5114 | Train Acc: 1.0000\n",
      "Val Loss:   0.3887 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3438 | Train Acc: 1.0000\n",
      "Val Loss:   0.2081 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2289 | Train Acc: 0.9710\n",
      "Val Loss:   0.1049 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1012 | Train Acc: 1.0000\n",
      "Val Loss:   0.0457 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0516 | Train Acc: 1.0000\n",
      "Val Loss:   0.0210 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0579 | Train Acc: 0.9855\n",
      "Val Loss:   0.0143 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6833 | Train Acc: 0.6232\n",
      "Val Loss:   0.6469 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6709 | Train Acc: 0.7246\n",
      "Val Loss:   0.6220 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6443 | Train Acc: 0.8696\n",
      "Val Loss:   0.5819 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6029 | Train Acc: 0.8986\n",
      "Val Loss:   0.5189 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5201 | Train Acc: 1.0000\n",
      "Val Loss:   0.3726 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3490 | Train Acc: 1.0000\n",
      "Val Loss:   0.1831 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1867 | Train Acc: 1.0000\n",
      "Val Loss:   0.0672 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0901 | Train Acc: 1.0000\n",
      "Val Loss:   0.0265 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0421 | Train Acc: 1.0000\n",
      "Val Loss:   0.0121 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.2159 | Train Acc: 0.9565\n",
      "Val Loss:   0.0079 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6884 | Train Acc: 0.5942\n",
      "Val Loss:   0.6456 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6729 | Train Acc: 0.6957\n",
      "Val Loss:   0.6256 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6624 | Train Acc: 0.7246\n",
      "Val Loss:   0.5959 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6288 | Train Acc: 0.9275\n",
      "Val Loss:   0.5501 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5652 | Train Acc: 0.9855\n",
      "Val Loss:   0.4567 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4274 | Train Acc: 1.0000\n",
      "Val Loss:   0.3077 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2345 | Train Acc: 1.0000\n",
      "Val Loss:   0.1532 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1289 | Train Acc: 1.0000\n",
      "Val Loss:   0.0678 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0622 | Train Acc: 0.9855\n",
      "Val Loss:   0.0337 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1915 | Train Acc: 0.9565\n",
      "Val Loss:   0.0241 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.7033 | Train Acc: 0.4348\n",
      "Val Loss:   0.7403 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6855 | Train Acc: 0.4348\n",
      "Val Loss:   0.7033 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6634 | Train Acc: 0.6522\n",
      "Val Loss:   0.6565 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6273 | Train Acc: 0.8841\n",
      "Val Loss:   0.5651 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5632 | Train Acc: 0.9565\n",
      "Val Loss:   0.3924 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3783 | Train Acc: 1.0000\n",
      "Val Loss:   0.1786 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2348 | Train Acc: 0.9855\n",
      "Val Loss:   0.0639 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1121 | Train Acc: 1.0000\n",
      "Val Loss:   0.0237 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0602 | Train Acc: 1.0000\n",
      "Val Loss:   0.0117 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1017 | Train Acc: 0.9710\n",
      "Val Loss:   0.0071 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6915 | Train Acc: 0.5072\n",
      "Val Loss:   0.6998 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6706 | Train Acc: 0.8261\n",
      "Val Loss:   0.6646 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6513 | Train Acc: 0.9275\n",
      "Val Loss:   0.6061 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5896 | Train Acc: 0.9710\n",
      "Val Loss:   0.4833 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4931 | Train Acc: 1.0000\n",
      "Val Loss:   0.2851 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3054 | Train Acc: 1.0000\n",
      "Val Loss:   0.0997 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1849 | Train Acc: 0.9855\n",
      "Val Loss:   0.0369 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0877 | Train Acc: 1.0000\n",
      "Val Loss:   0.0181 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0910 | Train Acc: 0.9855\n",
      "Val Loss:   0.0095 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0348 | Train Acc: 1.0000\n",
      "Val Loss:   0.0059 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.7021 | Train Acc: 0.4493\n",
      "Val Loss:   0.7177 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6865 | Train Acc: 0.5217\n",
      "Val Loss:   0.7006 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6630 | Train Acc: 0.7246\n",
      "Val Loss:   0.6585 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6218 | Train Acc: 0.9855\n",
      "Val Loss:   0.5854 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5450 | Train Acc: 1.0000\n",
      "Val Loss:   0.4160 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4000 | Train Acc: 1.0000\n",
      "Val Loss:   0.1803 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2421 | Train Acc: 1.0000\n",
      "Val Loss:   0.0548 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1306 | Train Acc: 1.0000\n",
      "Val Loss:   0.0188 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0643 | Train Acc: 1.0000\n",
      "Val Loss:   0.0093 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1196 | Train Acc: 0.9710\n",
      "Val Loss:   0.0058 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6975 | Train Acc: 0.4203\n",
      "Val Loss:   0.7061 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6890 | Train Acc: 0.4783\n",
      "Val Loss:   0.6890 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6792 | Train Acc: 0.6812\n",
      "Val Loss:   0.6607 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6466 | Train Acc: 0.8261\n",
      "Val Loss:   0.6119 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5916 | Train Acc: 1.0000\n",
      "Val Loss:   0.5090 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4765 | Train Acc: 1.0000\n",
      "Val Loss:   0.3174 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.3183 | Train Acc: 0.9855\n",
      "Val Loss:   0.1358 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1766 | Train Acc: 1.0000\n",
      "Val Loss:   0.0639 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0912 | Train Acc: 1.0000\n",
      "Val Loss:   0.0283 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0420 | Train Acc: 1.0000\n",
      "Val Loss:   0.0156 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6863 | Train Acc: 0.6377\n",
      "Val Loss:   0.6677 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6707 | Train Acc: 0.8261\n",
      "Val Loss:   0.6317 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6520 | Train Acc: 0.9710\n",
      "Val Loss:   0.5852 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5921 | Train Acc: 1.0000\n",
      "Val Loss:   0.4930 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4996 | Train Acc: 1.0000\n",
      "Val Loss:   0.3228 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3273 | Train Acc: 1.0000\n",
      "Val Loss:   0.1456 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1638 | Train Acc: 1.0000\n",
      "Val Loss:   0.0534 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0819 | Train Acc: 1.0000\n",
      "Val Loss:   0.0218 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0373 | Train Acc: 1.0000\n",
      "Val Loss:   0.0119 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.2945 | Train Acc: 0.9275\n",
      "Val Loss:   0.0078 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6881 | Train Acc: 0.5507\n",
      "Val Loss:   0.6377 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6708 | Train Acc: 0.5942\n",
      "Val Loss:   0.6163 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6535 | Train Acc: 0.5942\n",
      "Val Loss:   0.5802 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6185 | Train Acc: 0.7681\n",
      "Val Loss:   0.5105 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5314 | Train Acc: 0.9710\n",
      "Val Loss:   0.3771 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3972 | Train Acc: 1.0000\n",
      "Val Loss:   0.1819 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2258 | Train Acc: 1.0000\n",
      "Val Loss:   0.0672 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1218 | Train Acc: 1.0000\n",
      "Val Loss:   0.0245 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0514 | Train Acc: 1.0000\n",
      "Val Loss:   0.0118 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0302 | Train Acc: 1.0000\n",
      "Val Loss:   0.0072 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6820 | Train Acc: 0.7101\n",
      "Val Loss:   0.6683 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6715 | Train Acc: 0.8551\n",
      "Val Loss:   0.6505 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6508 | Train Acc: 0.9275\n",
      "Val Loss:   0.6181 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6120 | Train Acc: 0.9710\n",
      "Val Loss:   0.5712 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5275 | Train Acc: 1.0000\n",
      "Val Loss:   0.4650 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4060 | Train Acc: 1.0000\n",
      "Val Loss:   0.2789 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2164 | Train Acc: 1.0000\n",
      "Val Loss:   0.1114 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1020 | Train Acc: 1.0000\n",
      "Val Loss:   0.0397 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0514 | Train Acc: 1.0000\n",
      "Val Loss:   0.0168 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0253 | Train Acc: 1.0000\n",
      "Val Loss:   0.0093 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6921 | Train Acc: 0.5362\n",
      "Val Loss:   0.6855 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6781 | Train Acc: 0.7246\n",
      "Val Loss:   0.6612 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6630 | Train Acc: 0.9275\n",
      "Val Loss:   0.6323 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6196 | Train Acc: 0.9710\n",
      "Val Loss:   0.5779 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5240 | Train Acc: 1.0000\n",
      "Val Loss:   0.4494 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4060 | Train Acc: 0.9565\n",
      "Val Loss:   0.2534 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2057 | Train Acc: 1.0000\n",
      "Val Loss:   0.0954 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0959 | Train Acc: 1.0000\n",
      "Val Loss:   0.0364 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0503 | Train Acc: 1.0000\n",
      "Val Loss:   0.0179 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0335 | Train Acc: 1.0000\n",
      "Val Loss:   0.0105 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6851 | Train Acc: 0.5507\n",
      "Val Loss:   0.6177 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6708 | Train Acc: 0.6087\n",
      "Val Loss:   0.5984 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6490 | Train Acc: 0.7101\n",
      "Val Loss:   0.5604 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6072 | Train Acc: 0.9130\n",
      "Val Loss:   0.4930 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5235 | Train Acc: 1.0000\n",
      "Val Loss:   0.3641 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3433 | Train Acc: 1.0000\n",
      "Val Loss:   0.1923 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1832 | Train Acc: 1.0000\n",
      "Val Loss:   0.0786 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1877 | Train Acc: 0.9420\n",
      "Val Loss:   0.0363 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0502 | Train Acc: 1.0000\n",
      "Val Loss:   0.0202 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0394 | Train Acc: 1.0000\n",
      "Val Loss:   0.0119 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6885 | Train Acc: 0.6377\n",
      "Val Loss:   0.6545 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6745 | Train Acc: 0.7101\n",
      "Val Loss:   0.6298 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6576 | Train Acc: 0.8551\n",
      "Val Loss:   0.6050 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6331 | Train Acc: 0.9275\n",
      "Val Loss:   0.5566 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5584 | Train Acc: 1.0000\n",
      "Val Loss:   0.4718 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4412 | Train Acc: 1.0000\n",
      "Val Loss:   0.3098 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2534 | Train Acc: 1.0000\n",
      "Val Loss:   0.1582 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1402 | Train Acc: 1.0000\n",
      "Val Loss:   0.0665 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0623 | Train Acc: 1.0000\n",
      "Val Loss:   0.0292 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0776 | Train Acc: 0.9855\n",
      "Val Loss:   0.0163 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6934 | Train Acc: 0.5362\n",
      "Val Loss:   0.6928 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6770 | Train Acc: 0.7101\n",
      "Val Loss:   0.6541 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6611 | Train Acc: 0.8841\n",
      "Val Loss:   0.6047 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6199 | Train Acc: 0.9420\n",
      "Val Loss:   0.5272 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5250 | Train Acc: 0.9855\n",
      "Val Loss:   0.3440 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3604 | Train Acc: 1.0000\n",
      "Val Loss:   0.1465 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2061 | Train Acc: 1.0000\n",
      "Val Loss:   0.0483 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1963 | Train Acc: 0.9565\n",
      "Val Loss:   0.0366 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1824 | Train Acc: 0.9420\n",
      "Val Loss:   0.0242 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0594 | Train Acc: 1.0000\n",
      "Val Loss:   0.0149 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6900 | Train Acc: 0.5072\n",
      "Val Loss:   0.6642 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6752 | Train Acc: 0.8406\n",
      "Val Loss:   0.6382 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6498 | Train Acc: 0.9130\n",
      "Val Loss:   0.5869 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6045 | Train Acc: 1.0000\n",
      "Val Loss:   0.4683 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4923 | Train Acc: 1.0000\n",
      "Val Loss:   0.2583 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3710 | Train Acc: 0.9710\n",
      "Val Loss:   0.1006 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2410 | Train Acc: 1.0000\n",
      "Val Loss:   0.0433 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1472 | Train Acc: 1.0000\n",
      "Val Loss:   0.0192 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0840 | Train Acc: 1.0000\n",
      "Val Loss:   0.0110 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.2117 | Train Acc: 0.9565\n",
      "Val Loss:   0.0081 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6844 | Train Acc: 0.6812\n",
      "Val Loss:   0.6762 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6679 | Train Acc: 0.9130\n",
      "Val Loss:   0.6427 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6423 | Train Acc: 0.9130\n",
      "Val Loss:   0.5787 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6044 | Train Acc: 1.0000\n",
      "Val Loss:   0.4880 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5062 | Train Acc: 1.0000\n",
      "Val Loss:   0.3405 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3455 | Train Acc: 1.0000\n",
      "Val Loss:   0.1565 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1801 | Train Acc: 1.0000\n",
      "Val Loss:   0.0575 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0786 | Train Acc: 1.0000\n",
      "Val Loss:   0.0212 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1202 | Train Acc: 0.9710\n",
      "Val Loss:   0.0114 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0333 | Train Acc: 1.0000\n",
      "Val Loss:   0.0086 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6888 | Train Acc: 0.6522\n",
      "Val Loss:   0.6649 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6752 | Train Acc: 0.8116\n",
      "Val Loss:   0.6381 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6592 | Train Acc: 0.8696\n",
      "Val Loss:   0.5916 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6165 | Train Acc: 0.9855\n",
      "Val Loss:   0.5177 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5428 | Train Acc: 1.0000\n",
      "Val Loss:   0.3879 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3934 | Train Acc: 1.0000\n",
      "Val Loss:   0.2100 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2128 | Train Acc: 1.0000\n",
      "Val Loss:   0.0831 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0921 | Train Acc: 1.0000\n",
      "Val Loss:   0.0340 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0449 | Train Acc: 1.0000\n",
      "Val Loss:   0.0174 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0276 | Train Acc: 1.0000\n",
      "Val Loss:   0.0105 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6871 | Train Acc: 0.6087\n",
      "Val Loss:   0.6597 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6727 | Train Acc: 0.7826\n",
      "Val Loss:   0.6181 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6527 | Train Acc: 0.8406\n",
      "Val Loss:   0.5662 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6001 | Train Acc: 0.9565\n",
      "Val Loss:   0.4649 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5236 | Train Acc: 0.9710\n",
      "Val Loss:   0.2844 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3800 | Train Acc: 0.9855\n",
      "Val Loss:   0.1223 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2155 | Train Acc: 1.0000\n",
      "Val Loss:   0.0364 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1054 | Train Acc: 1.0000\n",
      "Val Loss:   0.0136 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0686 | Train Acc: 1.0000\n",
      "Val Loss:   0.0067 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0562 | Train Acc: 0.9855\n",
      "Val Loss:   0.0047 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6836 | Train Acc: 0.6377\n",
      "Val Loss:   0.6459 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6650 | Train Acc: 0.8116\n",
      "Val Loss:   0.6153 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6425 | Train Acc: 0.9710\n",
      "Val Loss:   0.5670 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5828 | Train Acc: 0.9855\n",
      "Val Loss:   0.4790 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4778 | Train Acc: 1.0000\n",
      "Val Loss:   0.3412 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3021 | Train Acc: 1.0000\n",
      "Val Loss:   0.1888 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1573 | Train Acc: 1.0000\n",
      "Val Loss:   0.0828 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0799 | Train Acc: 1.0000\n",
      "Val Loss:   0.0385 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0418 | Train Acc: 1.0000\n",
      "Val Loss:   0.0203 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0271 | Train Acc: 1.0000\n",
      "Val Loss:   0.0124 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6833 | Train Acc: 0.5942\n",
      "Val Loss:   0.6486 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6690 | Train Acc: 0.7246\n",
      "Val Loss:   0.6201 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6523 | Train Acc: 0.7826\n",
      "Val Loss:   0.5827 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6134 | Train Acc: 0.9130\n",
      "Val Loss:   0.5030 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5293 | Train Acc: 0.9710\n",
      "Val Loss:   0.3418 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3949 | Train Acc: 1.0000\n",
      "Val Loss:   0.1426 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2082 | Train Acc: 1.0000\n",
      "Val Loss:   0.0498 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1490 | Train Acc: 0.9855\n",
      "Val Loss:   0.0211 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.2610 | Train Acc: 0.9275\n",
      "Val Loss:   0.0150 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1784 | Train Acc: 0.9420\n",
      "Val Loss:   0.0094 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6882 | Train Acc: 0.5507\n",
      "Val Loss:   0.6446 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6662 | Train Acc: 0.8261\n",
      "Val Loss:   0.6135 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6410 | Train Acc: 0.8841\n",
      "Val Loss:   0.5518 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5967 | Train Acc: 0.9710\n",
      "Val Loss:   0.4488 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5009 | Train Acc: 1.0000\n",
      "Val Loss:   0.2765 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3394 | Train Acc: 1.0000\n",
      "Val Loss:   0.1220 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1614 | Train Acc: 1.0000\n",
      "Val Loss:   0.0485 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0828 | Train Acc: 1.0000\n",
      "Val Loss:   0.0206 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0367 | Train Acc: 1.0000\n",
      "Val Loss:   0.0104 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0195 | Train Acc: 1.0000\n",
      "Val Loss:   0.0061 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6926 | Train Acc: 0.5507\n",
      "Val Loss:   0.6804 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6862 | Train Acc: 0.6377\n",
      "Val Loss:   0.6639 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6642 | Train Acc: 0.8986\n",
      "Val Loss:   0.6342 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6445 | Train Acc: 0.9420\n",
      "Val Loss:   0.5725 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5746 | Train Acc: 0.9855\n",
      "Val Loss:   0.4366 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4407 | Train Acc: 1.0000\n",
      "Val Loss:   0.2335 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2340 | Train Acc: 1.0000\n",
      "Val Loss:   0.0949 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1200 | Train Acc: 1.0000\n",
      "Val Loss:   0.0386 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0483 | Train Acc: 1.0000\n",
      "Val Loss:   0.0190 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0229 | Train Acc: 1.0000\n",
      "Val Loss:   0.0112 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6859 | Train Acc: 0.5507\n",
      "Val Loss:   0.6466 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6724 | Train Acc: 0.5942\n",
      "Val Loss:   0.6209 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6481 | Train Acc: 0.7971\n",
      "Val Loss:   0.5669 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6053 | Train Acc: 0.9275\n",
      "Val Loss:   0.4547 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5201 | Train Acc: 1.0000\n",
      "Val Loss:   0.2808 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3712 | Train Acc: 1.0000\n",
      "Val Loss:   0.1035 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2193 | Train Acc: 1.0000\n",
      "Val Loss:   0.0376 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1329 | Train Acc: 1.0000\n",
      "Val Loss:   0.0170 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0697 | Train Acc: 1.0000\n",
      "Val Loss:   0.0095 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0825 | Train Acc: 0.9855\n",
      "Val Loss:   0.0064 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6888 | Train Acc: 0.5652\n",
      "Val Loss:   0.6481 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6755 | Train Acc: 0.5652\n",
      "Val Loss:   0.6388 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6613 | Train Acc: 0.5942\n",
      "Val Loss:   0.6217 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6318 | Train Acc: 0.7391\n",
      "Val Loss:   0.5659 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5762 | Train Acc: 0.9130\n",
      "Val Loss:   0.4505 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4555 | Train Acc: 1.0000\n",
      "Val Loss:   0.2262 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2861 | Train Acc: 1.0000\n",
      "Val Loss:   0.0635 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1432 | Train Acc: 1.0000\n",
      "Val Loss:   0.0211 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0797 | Train Acc: 1.0000\n",
      "Val Loss:   0.0095 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0422 | Train Acc: 1.0000\n",
      "Val Loss:   0.0057 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6897 | Train Acc: 0.5072\n",
      "Val Loss:   0.6633 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6736 | Train Acc: 0.6377\n",
      "Val Loss:   0.6493 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6462 | Train Acc: 0.7826\n",
      "Val Loss:   0.6323 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6156 | Train Acc: 0.9275\n",
      "Val Loss:   0.5885 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5284 | Train Acc: 0.9710\n",
      "Val Loss:   0.4892 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3734 | Train Acc: 1.0000\n",
      "Val Loss:   0.1896 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2145 | Train Acc: 1.0000\n",
      "Val Loss:   0.0561 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1273 | Train Acc: 1.0000\n",
      "Val Loss:   0.0205 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1269 | Train Acc: 0.9855\n",
      "Val Loss:   0.0121 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0773 | Train Acc: 0.9855\n",
      "Val Loss:   0.0103 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6920 | Train Acc: 0.5507\n",
      "Val Loss:   0.6706 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6810 | Train Acc: 0.7246\n",
      "Val Loss:   0.6613 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6637 | Train Acc: 0.9130\n",
      "Val Loss:   0.6431 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6393 | Train Acc: 0.9855\n",
      "Val Loss:   0.5948 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5799 | Train Acc: 1.0000\n",
      "Val Loss:   0.5212 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4721 | Train Acc: 1.0000\n",
      "Val Loss:   0.3881 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.3041 | Train Acc: 1.0000\n",
      "Val Loss:   0.2187 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1483 | Train Acc: 1.0000\n",
      "Val Loss:   0.0913 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0718 | Train Acc: 1.0000\n",
      "Val Loss:   0.0352 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0344 | Train Acc: 1.0000\n",
      "Val Loss:   0.0167 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6863 | Train Acc: 0.5652\n",
      "Val Loss:   0.6400 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6717 | Train Acc: 0.6377\n",
      "Val Loss:   0.6228 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6562 | Train Acc: 0.6812\n",
      "Val Loss:   0.5836 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6199 | Train Acc: 0.9130\n",
      "Val Loss:   0.5261 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5383 | Train Acc: 1.0000\n",
      "Val Loss:   0.3934 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3795 | Train Acc: 1.0000\n",
      "Val Loss:   0.1891 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2118 | Train Acc: 1.0000\n",
      "Val Loss:   0.0694 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1015 | Train Acc: 1.0000\n",
      "Val Loss:   0.0263 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.2706 | Train Acc: 0.9275\n",
      "Val Loss:   2.8801 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.6023 | Train Acc: 0.7826\n",
      "Val Loss:   0.0260 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6942 | Train Acc: 0.4638\n",
      "Val Loss:   0.7033 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6723 | Train Acc: 0.7681\n",
      "Val Loss:   0.6719 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6564 | Train Acc: 0.9710\n",
      "Val Loss:   0.6494 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6264 | Train Acc: 0.9855\n",
      "Val Loss:   0.5943 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5321 | Train Acc: 1.0000\n",
      "Val Loss:   0.4501 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3763 | Train Acc: 1.0000\n",
      "Val Loss:   0.2015 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1969 | Train Acc: 1.0000\n",
      "Val Loss:   0.0639 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0857 | Train Acc: 1.0000\n",
      "Val Loss:   0.0253 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1698 | Train Acc: 0.9710\n",
      "Val Loss:   0.0154 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0844 | Train Acc: 0.9855\n",
      "Val Loss:   0.0142 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6975 | Train Acc: 0.4783\n",
      "Val Loss:   0.7213 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6846 | Train Acc: 0.5072\n",
      "Val Loss:   0.6960 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6676 | Train Acc: 0.8696\n",
      "Val Loss:   0.6751 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6299 | Train Acc: 1.0000\n",
      "Val Loss:   0.6287 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5627 | Train Acc: 1.0000\n",
      "Val Loss:   0.5027 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4188 | Train Acc: 1.0000\n",
      "Val Loss:   0.2505 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2384 | Train Acc: 1.0000\n",
      "Val Loss:   0.0878 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1035 | Train Acc: 1.0000\n",
      "Val Loss:   0.0297 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0546 | Train Acc: 1.0000\n",
      "Val Loss:   0.0126 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0258 | Train Acc: 1.0000\n",
      "Val Loss:   0.0071 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.7035 | Train Acc: 0.4348\n",
      "Val Loss:   0.7375 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6925 | Train Acc: 0.4348\n",
      "Val Loss:   0.7233 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6739 | Train Acc: 0.5217\n",
      "Val Loss:   0.7140 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6478 | Train Acc: 0.7246\n",
      "Val Loss:   0.6920 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.6081 | Train Acc: 0.9130\n",
      "Val Loss:   0.6324 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.5024 | Train Acc: 1.0000\n",
      "Val Loss:   0.5660 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.3193 | Train Acc: 1.0000\n",
      "Val Loss:   0.2886 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.2081 | Train Acc: 0.9855\n",
      "Val Loss:   0.1372 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0829 | Train Acc: 1.0000\n",
      "Val Loss:   0.0835 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0869 | Train Acc: 0.9855\n",
      "Val Loss:   0.0314 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6901 | Train Acc: 0.5072\n",
      "Val Loss:   0.6822 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6775 | Train Acc: 0.7681\n",
      "Val Loss:   0.6762 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6641 | Train Acc: 0.8551\n",
      "Val Loss:   0.6528 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6286 | Train Acc: 0.9275\n",
      "Val Loss:   0.6279 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5590 | Train Acc: 1.0000\n",
      "Val Loss:   0.5259 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4144 | Train Acc: 1.0000\n",
      "Val Loss:   0.2176 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2471 | Train Acc: 1.0000\n",
      "Val Loss:   0.0724 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1180 | Train Acc: 1.0000\n",
      "Val Loss:   0.0283 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1421 | Train Acc: 0.9710\n",
      "Val Loss:   0.0154 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0376 | Train Acc: 1.0000\n",
      "Val Loss:   0.0141 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.7014 | Train Acc: 0.4348\n",
      "Val Loss:   0.7410 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6875 | Train Acc: 0.4203\n",
      "Val Loss:   0.7241 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6712 | Train Acc: 0.5362\n",
      "Val Loss:   0.7000 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6385 | Train Acc: 0.8116\n",
      "Val Loss:   0.6541 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5660 | Train Acc: 0.9855\n",
      "Val Loss:   0.5763 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4304 | Train Acc: 1.0000\n",
      "Val Loss:   0.3100 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2547 | Train Acc: 1.0000\n",
      "Val Loss:   0.1160 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1196 | Train Acc: 1.0000\n",
      "Val Loss:   0.0431 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1367 | Train Acc: 0.9710\n",
      "Val Loss:   0.0198 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0908 | Train Acc: 0.9855\n",
      "Val Loss:   3.7523 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6843 | Train Acc: 0.5652\n",
      "Val Loss:   0.6131 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6646 | Train Acc: 0.5652\n",
      "Val Loss:   0.6052 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6436 | Train Acc: 0.5797\n",
      "Val Loss:   0.5792 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6048 | Train Acc: 0.7101\n",
      "Val Loss:   0.5073 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5105 | Train Acc: 0.9710\n",
      "Val Loss:   0.3594 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3539 | Train Acc: 0.9855\n",
      "Val Loss:   0.1511 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2072 | Train Acc: 1.0000\n",
      "Val Loss:   0.0524 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1105 | Train Acc: 1.0000\n",
      "Val Loss:   0.0202 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0592 | Train Acc: 1.0000\n",
      "Val Loss:   0.0100 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0279 | Train Acc: 1.0000\n",
      "Val Loss:   0.0060 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.7028 | Train Acc: 0.4348\n",
      "Val Loss:   0.7696 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6886 | Train Acc: 0.4348\n",
      "Val Loss:   0.7415 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6720 | Train Acc: 0.4638\n",
      "Val Loss:   0.7038 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6321 | Train Acc: 0.8261\n",
      "Val Loss:   0.6502 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5630 | Train Acc: 0.9565\n",
      "Val Loss:   0.4954 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3917 | Train Acc: 1.0000\n",
      "Val Loss:   0.2534 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2364 | Train Acc: 1.0000\n",
      "Val Loss:   0.0832 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1025 | Train Acc: 1.0000\n",
      "Val Loss:   0.0306 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1876 | Train Acc: 0.9710\n",
      "Val Loss:   0.0210 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0349 | Train Acc: 1.0000\n",
      "Val Loss:   0.0172 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6881 | Train Acc: 0.6812\n",
      "Val Loss:   0.6798 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6717 | Train Acc: 0.7681\n",
      "Val Loss:   0.6617 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6415 | Train Acc: 0.9420\n",
      "Val Loss:   0.6115 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5889 | Train Acc: 0.9710\n",
      "Val Loss:   0.5112 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4874 | Train Acc: 1.0000\n",
      "Val Loss:   0.2873 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3191 | Train Acc: 1.0000\n",
      "Val Loss:   0.0884 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1954 | Train Acc: 0.9855\n",
      "Val Loss:   0.0337 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1139 | Train Acc: 1.0000\n",
      "Val Loss:   0.0154 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0827 | Train Acc: 0.9855\n",
      "Val Loss:   0.0078 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0479 | Train Acc: 0.9855\n",
      "Val Loss:   0.0062 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6871 | Train Acc: 0.6232\n",
      "Val Loss:   0.6985 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6732 | Train Acc: 0.7681\n",
      "Val Loss:   0.6734 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6513 | Train Acc: 0.9420\n",
      "Val Loss:   0.6455 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6018 | Train Acc: 1.0000\n",
      "Val Loss:   0.5836 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4949 | Train Acc: 1.0000\n",
      "Val Loss:   0.4246 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3428 | Train Acc: 0.9855\n",
      "Val Loss:   0.2140 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1947 | Train Acc: 1.0000\n",
      "Val Loss:   0.0721 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0935 | Train Acc: 1.0000\n",
      "Val Loss:   0.0229 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0859 | Train Acc: 0.9855\n",
      "Val Loss:   0.0116 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.1919 | Train Acc: 0.9565\n",
      "Val Loss:   0.0085 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6958 | Train Acc: 0.4348\n",
      "Val Loss:   0.7113 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6839 | Train Acc: 0.6087\n",
      "Val Loss:   0.6955 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6670 | Train Acc: 0.7826\n",
      "Val Loss:   0.6670 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6254 | Train Acc: 0.9710\n",
      "Val Loss:   0.6232 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5489 | Train Acc: 0.9855\n",
      "Val Loss:   0.5001 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4138 | Train Acc: 1.0000\n",
      "Val Loss:   0.2590 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2106 | Train Acc: 1.0000\n",
      "Val Loss:   0.0814 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0889 | Train Acc: 1.0000\n",
      "Val Loss:   0.0283 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0360 | Train Acc: 1.0000\n",
      "Val Loss:   0.0130 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0197 | Train Acc: 1.0000\n",
      "Val Loss:   0.0074 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6783 | Train Acc: 0.5652\n",
      "Val Loss:   0.6096 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6663 | Train Acc: 0.5797\n",
      "Val Loss:   0.5823 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6391 | Train Acc: 0.6232\n",
      "Val Loss:   0.5454 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.5965 | Train Acc: 0.8261\n",
      "Val Loss:   0.4624 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4932 | Train Acc: 1.0000\n",
      "Val Loss:   0.3136 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3494 | Train Acc: 1.0000\n",
      "Val Loss:   0.1561 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1770 | Train Acc: 1.0000\n",
      "Val Loss:   0.0597 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0805 | Train Acc: 1.0000\n",
      "Val Loss:   0.0263 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0362 | Train Acc: 1.0000\n",
      "Val Loss:   0.0131 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0272 | Train Acc: 1.0000\n",
      "Val Loss:   0.0076 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6949 | Train Acc: 0.4348\n",
      "Val Loss:   0.7067 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6828 | Train Acc: 0.5507\n",
      "Val Loss:   0.6927 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6583 | Train Acc: 0.7971\n",
      "Val Loss:   0.6633 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6253 | Train Acc: 0.9420\n",
      "Val Loss:   0.5967 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5245 | Train Acc: 1.0000\n",
      "Val Loss:   0.4144 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3719 | Train Acc: 1.0000\n",
      "Val Loss:   0.1608 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2052 | Train Acc: 1.0000\n",
      "Val Loss:   0.0518 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0927 | Train Acc: 1.0000\n",
      "Val Loss:   0.0206 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1008 | Train Acc: 0.9855\n",
      "Val Loss:   0.0127 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0289 | Train Acc: 1.0000\n",
      "Val Loss:   0.0093 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 1/10\n",
      "Train Loss: 0.6889 | Train Acc: 0.4783\n",
      "Val Loss:   0.7129 | Val Acc:   0.0000\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6760 | Train Acc: 0.6087\n",
      "Val Loss:   0.6841 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6512 | Train Acc: 0.8986\n",
      "Val Loss:   0.6522 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6005 | Train Acc: 0.9710\n",
      "Val Loss:   0.5737 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.4942 | Train Acc: 0.9710\n",
      "Val Loss:   0.4104 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.3180 | Train Acc: 1.0000\n",
      "Val Loss:   0.1966 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.1646 | Train Acc: 1.0000\n",
      "Val Loss:   0.0725 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.0854 | Train Acc: 1.0000\n",
      "Val Loss:   0.0275 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.0393 | Train Acc: 1.0000\n",
      "Val Loss:   0.0128 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0564 | Train Acc: 0.9855\n",
      "Val Loss:   0.0084 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "\n",
      "Global Accuracy:  0.9857 \n",
      "Global F1-Score:  0.9836 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "\n",
    "all_loo_preds = []      \n",
    "all_loo_labels = []     \n",
    "loo_accuracies = []\n",
    "loo_results = []  \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(loo.split(all_sequences)):\n",
    "    train_sequences = [all_sequences[i] for i in train_idx]\n",
    "    val_sequences = [all_sequences[i] for i in val_idx]\n",
    " \n",
    "    test_sample = all_sequences[val_idx[0]]\n",
    "\n",
    "    _, val_acc, preds, labels_true = run_single_experiment(\n",
    "        train_sequences, val_sequences, device, save_model=False\n",
    "    )\n",
    "\n",
    "    all_loo_preds.extend(preds)\n",
    "    all_loo_labels.extend(labels_true)\n",
    "    \n",
    "    loo_accuracies.append(val_acc)\n",
    "\n",
    "    loo_results.append({\n",
    "        'fold': fold,\n",
    "        'index': val_idx[0],\n",
    "        'sequence_name': test_sample['sequence_name'],\n",
    "        'true_label': labels_true[0],\n",
    "        'predicted_label': preds[0],\n",
    "        'correct': labels_true[0] == preds[0],\n",
    "        'label_name': test_sample['label']\n",
    "    })\n",
    "    \n",
    "\n",
    "global_accuracy = accuracy_score(all_loo_labels, all_loo_preds)\n",
    "global_f1 = f1_score(all_loo_labels, all_loo_preds)\n",
    "\n",
    "print(f\"\\nGlobal Accuracy:  {global_accuracy:.4f} \")\n",
    "print(f\"Global F1-Score:  {global_f1:.4f} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Liczba błędnych predykcji: 1/70\n",
      "\n",
      "Błędnie sklasyfikowane próbki:\n",
      "--------------------------------------------------------------------------------\n",
      "Fold  61 | Indeks:  61 | Sekwencja: adl-32-cam0-rgb           | Prawda: ADL  | Predykcja: FALL\n",
      "Statystyki błędnych predykcji:\n",
      "Całkowita liczba próbek: 70\n",
      "Poprawne predykcje: 69\n",
      "Błędne predykcje: 1\n",
      "Accuracy: 0.9857\n",
      "\n",
      "--- Analiza błędnych predykcji ---\n",
      "\n",
      "Fałszywe alarmy (ADL sklasyfikowany jako FALL):\n",
      "  Indeks  61: adl-32-cam0-rgb\n",
      "\n",
      "Pominięte upadki (FALL sklasyfikowany jako ADL):\n",
      "\n",
      "Wyniki zapisane do 'loo_results.csv'\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(loo_results)\n",
    "\n",
    "misclassified = [r for r in loo_results if not r['correct']]\n",
    "print(f\"\\nLiczba błędnych predykcji: {len(misclassified)}/{len(all_sequences)}\")\n",
    "\n",
    "if misclassified:\n",
    "    print(\"\\nBłędnie sklasyfikowane próbki:\")\n",
    "    print(\"-\" * 80)\n",
    "    for item in misclassified:\n",
    "        true_name = 'FALL' if item['true_label'] == 1 else 'ADL'\n",
    "        pred_name = 'FALL' if item['predicted_label'] == 1 else 'ADL'\n",
    "        print(f\"Fold {item['fold']:3d} | Indeks: {item['index']:3d} | \"\n",
    "              f\"Sekwencja: {item['sequence_name']:25s} | \"\n",
    "              f\"Prawda: {true_name:4s} | Predykcja: {pred_name:4s}\")\n",
    "\n",
    "\n",
    "print(\"Statystyki błędnych predykcji:\")\n",
    "print(f\"Całkowita liczba próbek: {len(results_df)}\")\n",
    "print(f\"Poprawne predykcje: {results_df['correct'].sum()}\")\n",
    "print(f\"Błędne predykcje: {(~results_df['correct']).sum()}\")\n",
    "print(f\"Accuracy: {results_df['correct'].mean():.4f}\")\n",
    "\n",
    "misclassified_df = results_df[~results_df['correct']]\n",
    "\n",
    "if len(misclassified_df) > 0:\n",
    "    print(\"\\n--- Analiza błędnych predykcji ---\")\n",
    "    print(\"\\nFałszywe alarmy (ADL sklasyfikowany jako FALL):\")\n",
    "    false_positives = misclassified_df[(misclassified_df['true_label'] == 0) & (misclassified_df['predicted_label'] == 1)]\n",
    "    for _, row in false_positives.iterrows():\n",
    "        print(f\"  Indeks {row['index']:3d}: {row['sequence_name']}\")\n",
    "    \n",
    "    print(f\"\\nPominięte upadki (FALL sklasyfikowany jako ADL):\")\n",
    "    false_negatives = misclassified_df[(misclassified_df['true_label'] == 1) & (misclassified_df['predicted_label'] == 0)]\n",
    "    for _, row in false_negatives.iterrows():\n",
    "        print(f\"  Indeks {row['index']:3d}: {row['sequence_name']}\")\n",
    "    \n",
    "    # zapiszemy do csv zeby miec w razie w\n",
    "    results_df.to_csv('loo_results.csv', index=False)\n",
    "    print(f\"\\nWyniki zapisane do 'loo_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b65e272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Brak Upadku       1.00      0.97      0.99        40\n",
      "      Upadek       0.97      1.00      0.98        30\n",
      "\n",
      "    accuracy                           0.99        70\n",
      "   macro avg       0.98      0.99      0.99        70\n",
      "weighted avg       0.99      0.99      0.99        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "results_array = np.array(loo_accuracies).reshape(1, -1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10), gridspec_kw={'height_ratios': [1, 3]})\n",
    "\n",
    "sns.heatmap(results_array, annot=False, cbar=False, cmap=['#e74c3c', '#2ecc71'], \n",
    "            linewidths=1, linecolor='white', ax=axes[0])\n",
    "axes[0].set_title('Mapa poprawności predykcji dla każdego przypadku', fontsize=14)\n",
    "axes[0].set_xlabel('Numer próbki / Foldu')\n",
    "axes[0].set_yticks([])\n",
    "\n",
    "\n",
    "cm = confusion_matrix(all_loo_labels, all_loo_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1], annot_kws={\"size\": 16})\n",
    "axes[1].set_title('Globalna Macierz Pomyłek (Suma z LOO)', fontsize=14)\n",
    "axes[1].set_xlabel('Przewidziana klasa', fontsize=12)\n",
    "axes[1].set_ylabel('Prawdziwa klasa', fontsize=12)\n",
    "axes[1].set_xticklabels(['Brak Upadku (0)', 'Upadek (1)'])\n",
    "axes[1].set_yticklabels(['Brak Upadku (0)', 'Upadek (1)'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_loo_labels, all_loo_preds, target_names=['Brak Upadku', 'Upadek']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0b213",
   "metadata": {},
   "source": [
    "### Trenowanie finalnego modelu\n",
    "\n",
    "Po przeprowadzeniu LOO cross-validation dla oceny wydajności, teraz trenujemy finalny model na pełnym zbiorze treningowym (train + val), który będzie użyty do testowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c1747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 1/10\n",
      "Train Loss: 0.6985 | Train Acc: 0.4429\n",
      "Val Loss:   0.6907 | Val Acc:   0.4286\n",
      "LR:         0.000100\n",
      "Epoka 2/10\n",
      "Train Loss: 0.6826 | Train Acc: 0.5143\n",
      "Val Loss:   0.6698 | Val Acc:   0.7143\n",
      "LR:         0.000100\n",
      "Epoka 3/10\n",
      "Train Loss: 0.6727 | Train Acc: 0.6429\n",
      "Val Loss:   0.6398 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 4/10\n",
      "Train Loss: 0.6322 | Train Acc: 0.9286\n",
      "Val Loss:   0.5880 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 5/10\n",
      "Train Loss: 0.5559 | Train Acc: 1.0000\n",
      "Val Loss:   0.4738 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 6/10\n",
      "Train Loss: 0.4239 | Train Acc: 1.0000\n",
      "Val Loss:   0.3005 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 7/10\n",
      "Train Loss: 0.2560 | Train Acc: 1.0000\n",
      "Val Loss:   0.1512 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 8/10\n",
      "Train Loss: 0.1375 | Train Acc: 1.0000\n",
      "Val Loss:   0.0710 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 9/10\n",
      "Train Loss: 0.1171 | Train Acc: 0.9714\n",
      "Val Loss:   0.0398 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "Epoka 10/10\n",
      "Train Loss: 0.0883 | Train Acc: 0.9857\n",
      "Val Loss:   0.0243 | Val Acc:   1.0000\n",
      "LR:         0.000100\n",
      "\n",
      "Zapisano model jako 'best_model.pth'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_train_sequences = train_sequences + val_sequences\n",
    "\n",
    "final_train_dataset = FallDetectionDataset(\n",
    "    final_train_sequences,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "final_val_dataset = FallDetectionDataset(\n",
    "    test_sequences,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "final_train_loader = DataLoader(\n",
    "    final_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "final_val_loader = DataLoader(\n",
    "    final_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "final_model = FallDetectionModel().to(device)\n",
    "\n",
    "final_criterion = nn.CrossEntropyLoss()\n",
    "final_optimizer = optim.Adam(final_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "final_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    final_optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "final_history = train_model(\n",
    "    model=final_model,\n",
    "    train_loader=final_train_loader,\n",
    "    val_loader=final_val_loader,\n",
    "    criterion=final_criterion,\n",
    "    optimizer=final_optimizer,\n",
    "    scheduler=final_scheduler,\n",
    "    num_epochs=EPOCHS,\n",
    "    device=device,\n",
    "    patience=5,\n",
    "    save_model=True,\n",
    "    model_path='best_model.pth'\n",
    ")\n",
    "\n",
    "print(\"\\n zapisano model jako 'best_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a77df534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zaladowanie najleposzego modelu i wyniki na zbiorze testowym\n",
      "\n",
      "Wyniki na zbiorze testowym:\n",
      "Test Loss: 0.0243\n",
      "Test Accuracy: 1.0000 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"zaladowanie najleposzego modelu i wyniki na zbiorze testowym\")\n",
    "\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "final_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "test_loss, test_acc, test_preds, test_labels = validate(\n",
    "    final_model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"\\nWyniki na zbiorze testowym:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73f0f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADL     1.0000    1.0000    1.0000         8\n",
      "        FALL     1.0000    1.0000    1.0000         6\n",
      "\n",
      "    accuracy                         1.0000        14\n",
      "   macro avg     1.0000    1.0000    1.0000        14\n",
      "weighted avg     1.0000    1.0000    1.0000        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class_names = ['ADL', 'FALL']\n",
    "\n",
    "report = classification_report(\n",
    "    test_labels, \n",
    "    test_preds, \n",
    "    target_names=class_names,\n",
    "    digits=4\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5cba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
